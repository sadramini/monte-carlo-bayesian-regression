# Monte Carlo Bayesian Regression

This project implements a **Bayesian Linear Regression model** estimated
using a **Random-Walk Metropolis--Hastings MCMC sampler**. The workflow
is fully reproducible and organized as a modular research-style
pipeline, including posterior inference, convergence diagnostics, Monte
Carlo error assessment, and posterior predictive evaluation.

The primary application is the **California Housing dataset**, and the
project also includes comparison with a classical OLS baseline.

------------------------------------------------------------------------

## ðŸŽ¯ Project Goals

-   Implement Bayesian linear regression from first principles
-   Use a handâ€‘written MCMC sampler (Randomâ€‘Walk Metropolis--Hastings)
-   Run multiple independent Markov chains
-   Evaluate convergence and sampler efficiency
-   Quantify Monte Carlo Standard Error (MCSE)
-   Perform posterior predictive checks
-   Compare against OLS regression as a frequentist benchmark
-   Produce clean, reproducible research outputs (tables + plots)

This repository is structured as a transparent and extensible **learning
and research project**, not just a script that prints results.

------------------------------------------------------------------------

## ðŸ§  Model Overview

The model assumes the standard Gaussian linear regression form

\[ y = X`\beta `{=tex}+ `\varepsilon `{=tex},
`\quad `{=tex}`\varepsilon `{=tex}`\sim `{=tex}`\mathcal `{=tex}N(0,
`\sigma`{=tex}\^2 I). \]

Priors:

-   (`\beta `{=tex}`\sim `{=tex}`\mathcal `{=tex}N(0,`\tau`{=tex}\^2 I))
-   (`\sigma`{=tex}\^2 `\sim `{=tex}`\text{Inverseâ€‘Gamma}`{=tex}(a,b))

The posterior is explored using a **Randomâ€‘Walk MH sampler** with:

-   multiple chains
-   chainâ€‘level adaptation settings
-   diagnostics stored to disk

------------------------------------------------------------------------

## ðŸ§© Project Structure

    .
    â”œâ”€â”€ data.py              # Load & preprocess dataset
    â”œâ”€â”€ model.py             # Likelihood + prior + posterior logâ€‘density
    â”œâ”€â”€ mcmc.py              # RWâ€‘Metropolis sampler + chain manager
    â”œâ”€â”€ diagnostics.py       # R-hat, ESS, MCSE, trace utilities
    â”œâ”€â”€ plots.py             # Trace, density, pair & PPC plots
    â”œâ”€â”€ predictive.py        # Posterior predictive simulation
    â”œâ”€â”€ run_analysis.py      # Main endâ€‘toâ€‘end pipeline
    â””â”€â”€ results/
        â”œâ”€â”€ plots/           # Saved figures
        â””â”€â”€ tables/          # CSV summaries and diagnostics

Each module is intentionally independent and reusable. The pipeline
script (`run_analysis.py`) orchestrates the full experiment.

------------------------------------------------------------------------

## ðŸš€ Workflow

Run the main analysis pipeline:

``` bash
python run_analysis.py
```

This performs:

1.  Load & preprocess data
2.  Initialize chains
3.  Run MCMC sampling
4.  Produce posterior summary tables
5.  Compute convergence diagnostics
6.  Evaluate MCSE
7.  Generate posterior predictive samples
8.  Compare results with OLS regression
9.  Save figures & tables to `results/`

All outputs are written to disk for full reproducibility.

------------------------------------------------------------------------

## ðŸ“Š Outputs

The pipeline generates:

### Tables (`results/tables/`)

-   posterior_summary.csv
-   diagnostics_rhat_ess_mcse.csv
-   chain_acceptance_rates.csv
-   ols_comparison.csv

### Plots (`results/plots/`)

-   trace plots
-   marginal posterior densities
-   chain comparison plots
-   posterior predictive checks
-   OLS vs posterior distributions

These are suitable for reports, coursework, or research documentation.

------------------------------------------------------------------------

## ðŸ§ª Reproducibility Philosophy

The `main` branch contains only:

-   validated sampler settings
-   stable diagnostic workflows
-   interpretable experiment outputs

Experimental tuning work is intentionally kept out of `main` to preserve
a clean reference implementation.

------------------------------------------------------------------------

## ðŸ§­ Possible Extensions

Ideas for future experimentation:

-   Alternative priors (Laplace, Horseshoe, ridgeâ€‘type shrinkage)
-   Hierarchical regression
-   Comparison with NUTS (Stan / PyMC) as a goldâ€‘standard reference
-   More advanced MH tuning strategies
-   Automatic stepâ€‘size adaptation

------------------------------------------------------------------------

## ðŸ™Œ Author

This project is developed by **Sadra** as a handsâ€‘on exploration of
Bayesian inference, MCMC sampling, and reproducible research pipelines.
