# Bayesian Linear Regression â€” California Housing (MCMC via Randomâ€‘Walk Metropolis)

This repository implements a full **Bayesian linear regression** analysis of the California Housing dataset using a
**componentâ€‘wise Randomâ€‘Walk Metropolisâ€“Hastings sampler**. The project reproduces the exact modeling and computational
approach of the original research notebook, but organizes the code into a clean, reproducible Python project structure.

All estimates, diagnostics, and posterior predictive quantities are generated directly from the MCMC chains and saved
into structured `results/plots/` and `results/tables/` folders for transparency and reproducibility.

---

## â­ Project Goals

- Implement Bayesian linear regression with:
  - standardized predictors and intercept
  - Normal prior on regression coefficients
  - Inverseâ€‘Gamma prior on noise variance
- Sample from the posterior via **Randomâ€‘Walk Metropolisâ€“Hastings**
- Diagnose convergence using:
  - Traceplots
  - Running means
  - Autocorrelation functions (ACF)
  - Effective Sample Size (ESS)
  - Splitâ€‘\(\hat R\)
  - Geweke zâ€‘scores
- Compare posterior summaries with OLS estimates
- Produce posterior predictive intervals on test data
- Save all outputs in a structured results directory

The statistical model, priors, sampler design, and diagnostics are **identical to the original project** â€” only the code
organization has changed.

---

## ğŸ§  Statistical Model

Let

\(
y \mid X, \beta, \sigma^2 \sim \mathcal N(X\beta,\ \sigma^2 I)
\)

**Priors**

\(
\beta \sim \mathcal N(0,\ \tau^2 I)
\)

\(
\sigma^2 \sim \text{Invâ€‘Gamma}(a_0,\ b_0)
\)

Sampling is performed in \(\beta\) and \(\log\sigma^2\) using:

- componentâ€‘wise randomâ€‘walk MH for coefficients
- scalar randomâ€‘walk MH for \(\log\sigma^2\)
- Jacobian correction for the logâ€‘variance transformation

Default hyperparameters (from the original project):

| Parameter | Value |
|----------|------:|
| \(\tau^2\) | 10 |
| \(a_0\) | 2 |
| \(b_0\) | 1 |

---

## ğŸ§© Project Structure

```
bayes-california-housing/
â”œâ”€â”€ bayes_regression/
â”‚   â”œâ”€â”€ data.py              # dataset loading + preprocessing
â”‚   â”œâ”€â”€ model.py             # priors + log posterior
â”‚   â”œâ”€â”€ mcmc.py              # Random-Walk MH sampler
â”‚   â”œâ”€â”€ diagnostics.py       # ESS, R-hat, Geweke, ACF
â”‚   â”œâ”€â”€ plots.py             # trace, running mean, acf plots
â”‚   â”œâ”€â”€ predictive.py        # posterior predictive samples
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ run_analysis.py          # main entrypoint to reproduce results
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ plots/               # generated figures
â”‚   â””â”€â”€ tables/              # csv output tables
â””â”€â”€ README.md
```

This layout makes the project:

- reproducible
- modular
- extensible
- researchâ€‘friendly

while preserving the exact original computation pipeline.

---

## â–¶ï¸ Running the Analysis

Install dependencies:

```bash
pip install -r requirements.txt
```

Run the full pipeline:

```bash
python run_analysis.py
```

This will:

1) load & standardize data  
2) fit OLS baseline  
3) run 4 independent MCMC chains  
4) compute convergence diagnostics  
5) generate posterior summaries  
6) compute predictive intervals  
7) save all outputs to `results/`

---

## ğŸ“ Output Artifacts

### ğŸ“Š Tables â€” saved in `results/tables/`

| File | Description |
|------|-------------|
| `posterior_summary.csv` | posterior means, SDs, credible intervals, \(P(\beta>0)\) |
| `diagnostics.csv` | ESS, splitâ€‘\(\hat R\), Geweke statistics |
| `mcse.csv` | Monteâ€‘Carlo Standard Errors |
| `posterior_predictive_test.csv` | predictive means & 95% intervals |
| `ols_estimates.csv` | OLS reference coefficients |

---

### ğŸ“‰ Plots â€” saved in `results/plots/`

- Traceplots for each parameter
- Runningâ€‘mean plots
- ACF plots for selected parameters
- \(\log\sigma^2\) convergence plots

These correspond exactly to the figures in the original project but are exported programmatically.

---

## ğŸ§ª Convergence Assessment

Convergence is evaluated using:

- Splitâ€‘\(\hat R \approx 1.00\) across chains
- ESS (min & mean over chains)
- Geweke zâ€‘scores
- visual trace stability
- ACF decay behavior

Where appropriate, longer burnâ€‘in or additional iterations may be used to
increase ESS while leaving the posterior unchanged.

---

## ğŸ¯ Interpretation Summary

Across chains, the posterior exhibits the same qualitative structure as the original work:

- Income (`MedInc`) â€” strong positive effect
- Rooms (`AveRooms`) â€” negative effect
- Bedrooms (`AveBedrms`) â€” positive effect
- Population â€” near zero effect
- Intercept â€” stable across runs
- Residual variance â€” consistent across chains

Posterior predictive intervals cover most test points appropriately,
indicating good calibration.

---

## ğŸ” Reproducibility Philosophy

This project is designed to:

- preserve the mathematical formulation of the original notebook
- maintain the *exact* sampler and diagnostics
- improve transparency and structure
- separate computation from experiment outputs

Nothing in the statistical workflow has been altered â€” only organized.

---

## ğŸ¤ Acknowledgements

Dataset: **California Housing â€” Scikitâ€‘Learn**  
Methods: Bayesian Linear Regression + Randomâ€‘Walk Metropolis  
Diagnostics: Gelmanâ€“Rubin, ESS, Geweke

---

## ğŸ“Œ Future Extensions (optional)

Potential followâ€‘up work:

- adaptive proposal scaling
- blockâ€‘update proposals for correlated predictors
- marginal likelihood estimation
- posterior predictive scoring metrics
- comparison with HMC / NUTS

These would extend capability without altering the current results pipeline.

---

## ğŸ“ Citation (if used academically)

If you use or adapt this project, please cite:

> Bayesian Linear Regression with Randomâ€‘Walk Metropolis Sampling â€”
> California Housing Posterior Analysis (2026).

---

## ğŸ‘ Author Notes

This repository was structured to preserve the **original code, modeling decisions,
and inferential results**, while making the project cleaner and easier to share,
reproduce, and review.

